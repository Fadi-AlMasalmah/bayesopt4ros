{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This notebook uses the classes bayesopt4ros and contextual_bayesopt4ros but without using ros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization Example (Not Contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util cell\n",
    "gets the config file and defines some classes to replace the ros2 related parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir: /home/fadi/ros2_ws_git_3/src/external_deps/bayesopt4ros/bayesopt4ros\n",
      "parent_dir: /home/fadi/ros2_ws_git_3/src/external_deps/bayesopt4ros\n",
      "../config/forrester_ucb.yaml\n"
     ]
    }
   ],
   "source": [
    "# this notebook uses the classes bayesopt4ros and contextual_bayesopt4ros but without using ros.\n",
    "# instead of creating a ros2 server\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from bayesopt4ros.bayesopt import BayesianOptimization\n",
    "from bayesopt4ros import util\n",
    "import numpy as np\n",
    "import test_objectives\n",
    "import torch\n",
    "\n",
    "# create a class that replaces the logger of ros2 with functions warning, info, debug and error\n",
    "class Logger:\n",
    "    def warning(self, msg):\n",
    "        print(f'WARNING: {msg}')\n",
    "    def info(self, msg):\n",
    "        print(f'INFO: {msg}')\n",
    "    def debug(self, msg):\n",
    "        print(f'DEBUG: {msg}')\n",
    "    def error(self, msg):\n",
    "        print(f'ERROR: {msg}')\n",
    "\n",
    "#create a class called goal, which has, goal.x_new, and goal.y_new\n",
    "class Goal:\n",
    "    def __init__(self, x_new, y_new, c_new= None):\n",
    "        self.x_new = x_new\n",
    "        self.y_new = y_new\n",
    "        self.c_new = c_new\n",
    "\n",
    "# get the path of the parent of the current directory\n",
    "current_dir = os.path.dirname(os.path.realpath(''))\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "print(f'current_dir: {current_dir}')\n",
    "print(f'parent_dir: {parent_dir}')\n",
    "yaml_file = glob.glob(os.path.join('../config', 'forrester_ucb.yaml'))[0]\n",
    "print(yaml_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: -----------\n",
      "INFO: feature_names: x1\n",
      "INFO: outcome_names: y1\n",
      "WARNING: dbg BayesianOptimization: _update_model, self.x_new == None or y_new = 0 for triggering\n",
      "x_new: tensor([0.5000], dtype=torch.float64)\n",
      "-----------\n",
      "iteration 0 :  x_new: 0.000, y_new: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m[INFO] [1712681586.471141515] [util]: Logging directory: BO_logs/forrester_ucb/2024-04-09-18-53-06\u001b[0m\n",
      "/home/fadi/.local/lib/python3.10/site-packages/botorch/models/transforms/outcome.py:304: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  stdvs = Y.std(dim=-2, keepdim=True)\n",
      "/home/fadi/.local/lib/python3.10/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 :  x_new: 1.000, y_new: 3.027\n",
      "iteration 2 :  x_new: 0.262, y_new: 15.830\n",
      "iteration 3 :  x_new: 0.363, y_new: -0.140\n",
      "iteration 4 :  x_new: 0.180, y_new: 0.011\n",
      "iteration 5 :  x_new: 0.161, y_new: -0.818\n",
      "iteration 6 :  x_new: 0.678, y_new: -0.939\n",
      "iteration 7 :  x_new: 0.773, y_new: -3.604\n",
      "iteration 8 :  x_new: 0.742, y_new: -5.877\n",
      "iteration 9 :  x_new: 0.757, y_new: -5.898\n",
      "WARNING: [BayesOpt] x_new is too close to existing data, proposing random x_new instead.\n",
      "iteration 10 :  x_new: 0.872, y_new: -6.021\n",
      "WARNING: [BayesOpt] x_new is too close to existing data, proposing random x_new instead.\n",
      "iteration 11 :  x_new: 0.422, y_new: 1.841\n",
      "WARNING: [BayesOpt] x_new is too close to existing data, proposing random x_new instead.\n",
      "iteration 12 :  x_new: 0.503, y_new: 0.247\n",
      "WARNING: [BayesOpt] x_new is too close to existing data, proposing random x_new instead.\n",
      "iteration 13 :  x_new: 0.743, y_new: 0.924\n",
      "WARNING: [BayesOpt] x_new is too close to existing data, proposing random x_new instead.\n",
      "iteration 14 :  x_new: 0.053, y_new: -5.921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_max = 15\n",
    "bo = BayesianOptimization.from_file(yaml_file, logger=Logger())\n",
    "func = test_objectives.Forrester()\n",
    "\n",
    "# triggering the BO algorithm\n",
    "goal = Goal(0, 0)\n",
    "x_new = bo.next(goal)\n",
    "print(f'x_new: {x_new}')\n",
    "print('-----------')\n",
    "\n",
    "# run the BO algorithm\n",
    "for i in range(N_max):\n",
    "    x_new_tensor = torch.atleast_2d(x_new.clone().detach())\n",
    "    # x_new_tensor = torch.atleast_2d(torch.tensor(x_new,dtype=torch.double))\n",
    "    y_new = func(x_new_tensor).squeeze().item()\n",
    "    goal = Goal(x_new, y_new)\n",
    "    x_new = bo.next(goal)\n",
    "    print(f'iteration {i} :  x_new: {x_new.item():.3f}, y_new: {y_new:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value found by the BO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt = tensor([0.7571], dtype=torch.float64)\n",
      "y_opt = -6.026422664372911\n",
      "x_best = tensor([0.7567], dtype=torch.float64)\n",
      "y_best = -6.020596949238973\n"
     ]
    }
   ],
   "source": [
    "x_opt, f_opt = bo.get_optimal_parameters()\n",
    "x_best, y_best = bo.get_best_observation()\n",
    "\n",
    "print(f'x_opt = {x_opt}')\n",
    "print(f'y_opt = {f_opt}')\n",
    "\n",
    "print(f'x_best = {x_best}')\n",
    "print(f'y_best = {y_best}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Bayesian Optimization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/contextual_forrester_ucb.yaml\n",
      "WARNING: dbg BayesianOptimization: _update_model, self.x_new == None or y_new = 0 for triggering, context = tensor([12.6570], dtype=torch.float64)\n",
      "x_new: tensor([0.5000], dtype=torch.float64)\n",
      "iteration 0 :  x_new: 0.750, y_new: 0.909, c_new: 11.096\n",
      "iteration 1 :  x_new: 0.250, y_new: -3.219, c_new: 7.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m[INFO] [1712685718.485999639] [util]: Logging directory: BO_logs/contextual_forrester_ucb/2024-04-09-20-01-58\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2 :  x_new: 0.375, y_new: -2.200, c_new: 14.773\n",
      "iteration 3 :  x_new: 0.326, y_new: -1.817, c_new: 20.271\n",
      "iteration 4 :  x_new: 0.972, y_new: -3.532, c_new: 11.361\n",
      "iteration 5 :  x_new: 0.678, y_new: 19.783, c_new: 20.896\n",
      "iteration 6 :  x_new: 0.000, y_new: 0.139, c_new: 7.113\n",
      "iteration 7 :  x_new: 0.107, y_new: -0.529, c_new: 15.440\n",
      "iteration 8 :  x_new: 0.635, y_new: -6.828, c_new: 8.723\n",
      "iteration 9 :  x_new: 0.146, y_new: -0.328, c_new: 11.004\n",
      "iteration 10 :  x_new: 0.762, y_new: -4.878, c_new: 3.121\n",
      "iteration 11 :  x_new: 0.000, y_new: -5.193, c_new: 12.229\n",
      "iteration 12 :  x_new: 0.202, y_new: -3.087, c_new: 16.708\n",
      "iteration 13 :  x_new: 0.061, y_new: -5.597, c_new: 15.487\n",
      "iteration 14 :  x_new: 0.085, y_new: -6.460, c_new: 13.181\n",
      "iteration 15 :  x_new: 0.433, y_new: -5.831, c_new: 0.774\n",
      "iteration 16 :  x_new: 0.086, y_new: 0.280, c_new: 21.167\n",
      "iteration 17 :  x_new: 0.717, y_new: -9.143, c_new: 2.683\n",
      "iteration 18 :  x_new: 0.114, y_new: -4.683, c_new: 8.452\n",
      "iteration 19 :  x_new: 0.119, y_new: -4.107, c_new: 20.022\n",
      "iteration 20 :  x_new: 0.736, y_new: -8.518, c_new: 8.554\n",
      "iteration 21 :  x_new: 0.095, y_new: -3.776, c_new: 17.014\n",
      "iteration 22 :  x_new: 0.089, y_new: -7.459, c_new: 18.680\n",
      "iteration 23 :  x_new: 0.754, y_new: -8.126, c_new: 1.158\n",
      "iteration 24 :  x_new: 0.077, y_new: -5.722, c_new: 21.521\n",
      "iteration 25 :  x_new: 0.098, y_new: -9.257, c_new: 17.489\n",
      "iteration 26 :  x_new: 0.115, y_new: -7.653, c_new: 9.272\n",
      "iteration 27 :  x_new: 0.111, y_new: -4.425, c_new: 11.893\n",
      "iteration 28 :  x_new: 0.092, y_new: -5.438, c_new: 20.021\n",
      "iteration 29 :  x_new: 0.105, y_new: -8.678, c_new: 16.074\n",
      "iteration 30 :  x_new: 0.751, y_new: -7.083, c_new: 5.213\n",
      "iteration 31 :  x_new: 0.750, y_new: -4.692, c_new: 2.311\n",
      "iteration 32 :  x_new: 0.113, y_new: -5.417, c_new: 9.925\n",
      "iteration 33 :  x_new: 0.763, y_new: -4.675, c_new: 0.271\n",
      "iteration 34 :  x_new: 0.751, y_new: -5.933, c_new: 0.447\n"
     ]
    }
   ],
   "source": [
    "# this notebook uses the classes bayesopt4ros and contextual_bayesopt4ros but without using ros.\n",
    "# instead of creating a ros2 server\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from bayesopt4ros.contextual_bayesopt import ContextualBayesianOptimization \n",
    "from bayesopt4ros import util\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "cbo_yaml_file = glob.glob(os.path.join('../config', 'contextual_forrester_ucb.yaml'))[0]\n",
    "print(cbo_yaml_file)\n",
    "func = test_objectives.ContextualForrester()\n",
    "\n",
    "def sample_context(self) -> np.ndarray:\n",
    "        \"\"\"Samples a random context variable to emulate the client.\"\"\"\n",
    "        context_bounds = [b for b in self.func._bounds[self.func.input_dim :]]\n",
    "        # context_bounds = [[-1,22]]\n",
    "        context = torch.tensor([np.random.uniform(b[0], b[1]) for b in context_bounds],dtype=torch.double)\n",
    "        return context\n",
    "\n",
    "N_max = 35\n",
    "cbo = ContextualBayesianOptimization.from_file(cbo_yaml_file, logger=Logger())\n",
    "\n",
    "# triggering the CBO algorithm\n",
    "c_prev = sample_context(cbo)\n",
    "goal = Goal(0, 0, c_prev)\n",
    "x_new = cbo.next(goal)\n",
    "print(f'x_new: {x_new}')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "for i in range(N_max):\n",
    "        # xc_new = torch.cat((torch.tensor(x_new,dtype=torch.double), c_prev))\n",
    "        xc_new = torch.cat((x_new.clone().detach(), c_prev))\n",
    "        xc_new_tensor = torch.atleast_2d(xc_new.clone().detach())\n",
    "        y_new = func(xc_new_tensor).squeeze().item()\n",
    "\n",
    "        c_new = sample_context(cbo)\n",
    "        x_new = cbo.next(Goal(x_new, y_new, c_new))\n",
    "        c_prev = c_new\n",
    "        print(f'iteration {i} :  x_new: {x_new.item():.3f}, y_new: {y_new:.3f}, c_new: {c_new.item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: [0.0]| x_opt: [0.757], actual: 0.756 | f_opt: -6.021, actual: -6.015\n",
      "context: [2.0]| x_opt: [0.755], actual: 0.755 | f_opt: -5.508, actual: -5.513\n",
      "context: [4.0]| x_opt: [0.753], actual: 0.753 | f_opt: -4.999, actual: -5.002\n",
      "context: [6.0]| x_opt: [0.751], actual: 0.751 | f_opt: -4.494, actual: -4.495\n",
      "context: [8.0]| x_opt: [0.749], actual: 0.749 | f_opt: -3.993, actual: -3.993\n",
      "context: [10.0]| x_opt: [0.115], actual: 0.116 | f_opt: -4.705, actual: -4.705\n",
      "context: [12.0]| x_opt: [0.11], actual: 0.111 | f_opt: -5.48, actual: -5.481\n",
      "context: [14.0]| x_opt: [0.106], actual: 0.106 | f_opt: -6.264, actual: -6.264\n",
      "context: [16.0]| x_opt: [0.101], actual: 0.101 | f_opt: -7.057, actual: -7.057\n",
      "context: [18.0]| x_opt: [0.097], actual: 0.096 | f_opt: -7.859, actual: -7.863\n",
      "context: [20.0]| x_opt: [0.092], actual: 0.092 | f_opt: -8.67, actual: -8.674\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# testing the learned optimal parameters\n",
    "results = []\n",
    "num_test_points = len(func._test_contexts)\n",
    "# testing on the context points\n",
    "for context in func._test_contexts:\n",
    "       results.append(cbo.get_optimal_parameters(context))\n",
    "# print(results)\n",
    "\n",
    "id = 0\n",
    "for context, x_opt, f_opt in zip(\n",
    "            func._test_contexts,\n",
    "            func._contextual_optimizer,\n",
    "            func._contextual_optimal_values,\n",
    "        ):\n",
    "            result = results[id]\n",
    "            print(f'context: {context}| x_opt: {x_opt}, actual: {result[0].item():.3f} | f_opt: {f_opt}, actual: {result[1].item():.3f}')\n",
    "\n",
    "            np.testing.assert_almost_equal(result[0], x_opt, decimal=2)\n",
    "            np.testing.assert_almost_equal(result[1], f_opt, decimal=2)\n",
    "            id += 1\n",
    "        \n",
    "print('All tests passed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
